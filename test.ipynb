{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from modules import AEC_builder\n",
    "\n",
    "import os\n",
    "# GPU selection\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='5'\n",
    "\n",
    "nb_layer = 1\n",
    "_encoder = AEC_builder.Encoder(input_shape=(2000, 16, 1), nb_layer=nb_layer, padding='same', kernel_size=(10,3), strides=(1,1), pool_size=(5,3), pool_strides=(2,2))\n",
    "_encoder.build()\n",
    "\n",
    "if not(_encoder.error_shape):\n",
    "    model = _encoder.model\n",
    "    model.summary()\n",
    "\n",
    "    # _bottle_neck = AEC_builder.BottleNeck(_encoder=_encoder.model, use_DENSE_OR_GAP='DENSE')\n",
    "    # _bottle_neck.build()\n",
    "    # model2 = _bottle_neck.model\n",
    "    # model2.summary()\n",
    "    \n",
    "    # model3 = _bottle_neck.decoder\n",
    "    # model3.summary()\n",
    "\n",
    "    # _decoder = AEC_builder.Decoder(_bottleneck=_bottle_neck.decoder, nb_layer=nb_layer, use_UPSAMPLE_OR_DECONV='UPSAMPLE', padding='same', kernel_size=(10,3), strides=(2,2), pool_size=(2, 2))\n",
    "    # _decoder.build()\n",
    "    # model4 = _decoder.model\n",
    "    # model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.output\n",
    "b = Flatten()(a)\n",
    "b = Dense(b.shape[1])(b)\n",
    "c = Model(inputs=model.input, outputs=b)\n",
    "c.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from modules.utils import append_default_path\n",
    "from modules import AEC_builder\n",
    "\n",
    "def getTupleFromStr(_str):\n",
    "    width = _str.split(',')[0]\n",
    "    height = _str.split(',')[1]\n",
    "    \n",
    "    width = int(width.split('(')[1])\n",
    "    height = int(height.split(')')[0])\n",
    "    \n",
    "    return (width, height)\n",
    "\n",
    "def get_ExperimentInfo():\n",
    "    path_module, path_csv, path_scalogram = append_default_path()\n",
    "    df_experiment = pd.read_excel(os.path.join(path_csv, 'AEC_experiments.xlsx'), index_col=0)\n",
    "    return df_experiment\n",
    "\n",
    "def get_PARAMS_from_ExperimentInfo(temp_experiment):\n",
    "    encoder_PARAMS = {\n",
    "        'nb_layer' : temp_experiment['nb_layer'],\n",
    "        'kernel_size' : (temp_experiment['kernel_width'], (temp_experiment['kernel_height'])),\n",
    "        'strides' : (temp_experiment['strides_width'], temp_experiment['strides_height']),\n",
    "        'padding' : temp_experiment['padding'],\n",
    "        'act_selection' : temp_experiment['act_selection'],\n",
    "        'pool_size' : (temp_experiment['max_pool_width'], temp_experiment['max_pool_height']),\n",
    "        'pool_strides' : (temp_experiment['max_pool_strides_width'], temp_experiment['max_pool_strides_height'])   \n",
    "    }\n",
    "    \n",
    "    bottleneck_PARAMS = {\n",
    "        'vector_len' : temp_experiment['vector_len'],\n",
    "        'act_selection' : temp_experiment['act_selection'],\n",
    "        'use_DENSE_OR_GAP' : temp_experiment['use_DENSE_OR_GAP']\n",
    "    }\n",
    "    \n",
    "    decoder_PARAMS = {\n",
    "        'nb_layer' : temp_experiment['nb_layer'],\n",
    "        'use_UPSAMPLE_OR_DECONV' : temp_experiment['use_UPSAMPLE_OR_DECONV'],\n",
    "        'kernel_size' : (temp_experiment['decoder_kernel_width'], temp_experiment['decoder_kernel_height']),\n",
    "        'strides' : (temp_experiment['decoder_strides_width'], temp_experiment['decoder_strides_height']),\n",
    "        'padding' : temp_experiment['padding'],\n",
    "        'act_selection' : temp_experiment['act_selection'],\n",
    "        'pool_size' : (temp_experiment['decoder_pool_width'], temp_experiment['decoder_pool_height'])        \n",
    "    }\n",
    "\n",
    "    return encoder_PARAMS, bottleneck_PARAMS, decoder_PARAMS\n",
    "\n",
    "\n",
    "def get_model_with_experiment_info(temp_experiment):\n",
    "    encoder_PARAMS, bottleneck_PARAMS, decoder_PARAMS = get_PARAMS_from_ExperimentInfo(temp_experiment)\n",
    "    _encoder = AEC_builder.Encoder(**encoder_PARAMS)\n",
    "    _encoder.build()\n",
    "    \n",
    "    bottleneck_PARAMS['_encoder'] = _encoder.model\n",
    "    _bottle_neck = AEC_builder.BottleNeck(**bottleneck_PARAMS)\n",
    "    _bottle_neck.build()\n",
    "    \n",
    "    decoder_PARAMS['_bottleneck'] = _bottle_neck.decoder\n",
    "    _decoder = AEC_builder.Decoder(**decoder_PARAMS)\n",
    "    _decoder.build()\n",
    "    \n",
    "    return _decoder.model\n",
    "    \n",
    "\n",
    "df_experiment = get_ExperimentInfo()\n",
    "display(df_experiment)\n",
    "\n",
    "model = get_model_with_experiment_info(df_experiment.loc[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape, UpSampling2D, Dropout\n",
    "from tensorflow.keras.layers import Conv3D, Conv3DTranspose, PReLU, BatchNormalization, MaxPool3D, Input, Conv2D, Conv2DTranspose, MaxPool2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "def ConvolutionalAutoencoder_v05(vector_len=30):\n",
    "    weight_decay=0.0005\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=24,\n",
    "                        input_shape=(2000, 16, 1),\n",
    "                        kernel_size=(10, 2),\n",
    "                        strides=(1, 1),\n",
    "                        kernel_regularizer=regularizers.l2(l=weight_decay),\n",
    "                        padding='valid', name=\"Conv1\"))\n",
    "    model.add(BatchNormalization(name=\"BN1\"))\n",
    "    model.add(PReLU(name=\"PReLU1\"))\n",
    "\n",
    "    model.add(Conv2D(filters=48,\n",
    "                        kernel_size=(10, 2),\n",
    "                        strides=(2, 1),\n",
    "                        kernel_regularizer=regularizers.l2(l=weight_decay),\n",
    "                        padding='valid', name=\"Conv2\"))\n",
    "    model.add(BatchNormalization(name=\"BN2\"))\n",
    "    model.add(PReLU(name=\"PReLU2\"))\n",
    "\n",
    "    model.add(MaxPool2D(pool_size=(5, 2),\n",
    "                        strides=(2, 1), name=\"Pool1\"))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=vector_len, name='embedding'))\n",
    "\n",
    "    model.add(Dense(units=494*14*48, activation='relu'))\n",
    "\n",
    "    model.add(Reshape((494,14,48)))\n",
    "\n",
    "    model.add(Conv2DTranspose(filters=24,\n",
    "                                kernel_size=(10, 2),\n",
    "                                kernel_regularizer=regularizers.l2(\n",
    "                                    l=weight_decay),\n",
    "                                strides=(2, 1), name=\"Deconv1\", padding='valid'))\n",
    "    model.add(BatchNormalization(name=\"BN3\"))\n",
    "    model.add(PReLU(name=\"PReLU3\"))\n",
    "    model.add(Conv2DTranspose(filters=1,\n",
    "                                kernel_size=(10, 2),\n",
    "                                kernel_regularizer=regularizers.l2(\n",
    "                                    l=weight_decay),\n",
    "                                strides=(2, 1), name=\"Deconv2\", padding='valid'))\n",
    "    model.add(BatchNormalization(name=\"BN4\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_v05 = ConvolutionalAutoencoder_v05()\n",
    "model_v05.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# GPU selection\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='5'\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/home/yschoi/INS_Clustering/Deep_clustering_v02/results/1/weights.h5')\n",
    "train_data = np.load('./data'+'/np_scalograms_1ch_train.npy')\n",
    "test_data = np.load('./data'+'/np_scalograms_1ch_test.npy')\n",
    "train_data_pred = model.predict(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "# from modules.model_utils import custom_corr\n",
    "\n",
    "def custom_corr(X_true, X_pred):\n",
    "    corr_train = []\n",
    "    for i in range(len(X_true)):\n",
    "        temp_corr = np.corrcoef(K.flatten(tf.squeeze(X_true[i])),\\\n",
    "                                K.flatten(tf.squeeze(X_pred[i])))[0,1]\n",
    "        corr_train.append(temp_corr)\n",
    "        \n",
    "    return np.mean(corr_train)\n",
    "\n",
    "def corr_keras(X_true, X_pred):\n",
    "    corr = tf.py_function(func=custom_corr, inp=[X_true, X_pred], Tout=tf.float32, name='corr')\n",
    "    return corr\n",
    "\n",
    "corr_keras(train_data, train_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model_utils import custom_corr\n",
    "\n",
    "print(custom_corr(train_data, train_data_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_train = []\n",
    "for i in range(len(train_data)):\n",
    "    temp_corr = np.corrcoef(train_data[i].squeeze().flatten(),\\\n",
    "                            train_data_pred[i].squeeze().flatten())[0,1]\n",
    "    corr_train.append(temp_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "print(\"mean corr: {}\".format(np.mean(corr_train)))\n",
    "sns.histplot(data=corr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_corr(X_test, X_test_pred):\n",
    "    for i in range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('tf27')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d04a8f8024b2dd9fbb605282604f2d432b6e7df7fca44a5deed08a1a683bf6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
